import requests
import json
import re
import plugins
from bridge.reply import Reply, ReplyType
from bridge.context import ContextType
from channel.chat_message import ChatMessage
from plugins import *
from common.log import logger
from common.expired_dict import ExpiredDict
import os
from docx import Document
import markdown
import fitz
from openpyxl import load_workbook
import csv
from bs4 import BeautifulSoup
from pptx import Presentation
from PIL import Image
import base64
import html
import importlib.util
import urllib3

# ç¦ç”¨ä¸å®‰å…¨è¯·æ±‚è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†openai
try:
    from openai import OpenAI
    has_openai = True
except ImportError:
    has_openai = False

# Moved remove_markdown function here
def remove_markdown(text):
    # æ›¿æ¢Markdownçš„ç²—ä½“æ ‡è®°
    text = text.replace("**", "")
    # æ›¿æ¢Markdownçš„æ ‡é¢˜æ ‡è®°
    text = text.replace("### ", "").replace("## ", "").replace("# ", "")
    return text

EXTENSION_TO_TYPE = {
    'pdf': 'pdf',
    'doc': 'docx', 'docx': 'docx',
    'md': 'md',
    'txt': 'txt',
    'xls': 'excel', 'xlsx': 'excel',
    'csv': 'csv',
    'html': 'html', 'htm': 'html',
    'ppt': 'ppt', 'pptx': 'ppt'
}

@plugins.register(
    name="sum4all",
    desire_priority=2,
    desc="A plugin for summarizing all things",
    version="0.7.11",
    author="fatwang2",
)

class sum4all(Plugin):
    def __init__(self):
        super().__init__()
        try:
            curdir = os.path.dirname(__file__)
            config_path = os.path.join(curdir, "config.json")
            if os.path.exists(config_path):
                with open(config_path, "r", encoding="utf-8") as f:
                    self.config = json.load(f)
            else:
                # ä½¿ç”¨çˆ¶ç±»çš„æ–¹æ³•æ¥åŠ è½½é…ç½®
                self.config = super().load_config()

                if not self.config:
                    raise Exception("config.json not found")
            # è®¾ç½®äº‹ä»¶å¤„ç†å‡½æ•°
            self.handlers[Event.ON_HANDLE_CONTEXT] = self.on_handle_context
            self.params_cache = ExpiredDict(300)

            
            # ä»é…ç½®ä¸­æå–æ‰€éœ€çš„è®¾ç½®
            self.keys = self.config.get("keys", {})
            self.url_sum = self.config.get("url_sum", {})
            self.search_sum = self.config.get("search_sum", {})
            self.file_sum = self.config.get("file_sum", {})
            self.image_sum = self.config.get("image_sum", {})
            self.note = self.config.get("note", {})

            self.sum4all_key = self.keys.get("sum4all_key", "")
            self.search1api_key = self.keys.get("search1api_key", "")
            self.gemini_key = self.keys.get("gemini_key", "")
            self.bibigpt_key = self.keys.get("bibigpt_key", "")
            self.outputLanguage = self.keys.get("outputLanguage", "zh-CN")
            self.opensum_key = self.keys.get("opensum_key", "")
            self.open_ai_api_key = self.keys.get("open_ai_api_key", "")
            self.model = self.keys.get("model", "gpt-3.5-turbo")
            self.open_ai_api_base = self.keys.get("open_ai_api_base", "https://api.openai.com/v1")
            self.azure_deployment_id = self.keys.get("azure_deployment_id", "")
            self.xunfei_app_id = self.keys.get("xunfei_app_id", "")
            self.xunfei_api_key = self.keys.get("xunfei_api_key", "")
            self.xunfei_api_secret = self.keys.get("xunfei_api_secret", "")
            self.perplexity_key = self.keys.get("perplexity_key", "")
            self.flomo_key = self.keys.get("flomo_key", "")
            # Load Aliyun config
            self.aliyun_key = self.keys.get("aliyun_key", "")
            self.aliyun_base_url = self.keys.get("aliyun_base_url", "https://dashscope.aliyuncs.com/compatible-mode/v1")
            self.aliyun_model = self.keys.get("aliyun_model", "qwen-max")
            self.aliyun_vl_model = self.keys.get("aliyun_vl_model", "qwen-vl-max-latest")
            self.aliyun_sum_model = self.keys.get("aliyun_sum_model", "qwen-long")
            # Load SiliconFlow (sflow) config - CORRECTED
            # self.sflow_key = self.keys.get("sflow_key", "") # Old incorrect key
            # self.sflow_base_url = self.keys.get("sflow_base_url", "") # Old incorrect key
            # self.sflow_model = self.keys.get("sflow_model", "") # Old incorrect key - missing distinction
            self.siliconflow_key = self.keys.get("siliconflow_key", "") # Use correct key from user
            self.siliconflow_base_url = self.keys.get("siliconflow_base_url", "") # Use correct key from user
            self.siliconflow_vl_model = self.keys.get("siliconflow_vl_model", "") # Load VL model
            self.siliconflow_sum_model = self.keys.get("siliconflow_sum_model", "") # Load SUM model

            # æå–sumæœåŠ¡çš„é…ç½®
            self.url_sum_enabled = self.url_sum.get("enabled", False)
            self.url_sum_service = self.url_sum.get("service", "")
            self.url_sum_group = self.url_sum.get("group", True)
            self.url_sum_qa_enabled = self.url_sum.get("qa_enabled", True)
            self.url_sum_qa_prefix = self.url_sum.get("qa_prefix", "é—®")
            self.url_sum_prompt = self.url_sum.get("prompt", "")

            self.search_sum_enabled = self.search_sum.get("enabled", False)
            self.search_sum_service = self.search_sum.get("service", "")
            self.search_service = self.search_sum.get("search_service", "duckduckgo")
            self.search_sum_group = self.search_sum.get("group", True)
            self.search_sum_search_prefix = self.search_sum.get("search_prefix", "æœ")
            self.search_sum_prompt = self.search_sum.get("prompt", "")

            self.file_sum_enabled = self.file_sum.get("enabled", False)
            self.file_sum_service = self.file_sum.get("service", "")
            self.max_file_size = self.file_sum.get("max_file_size", 15000)
            self.file_sum_group = self.file_sum.get("group", True)
            self.file_sum_qa_prefix = self.file_sum.get("qa_prefix", "é—®")
            self.file_sum_prompt = self.file_sum.get("prompt", "")

            self.image_sum_enabled = self.image_sum.get("enabled", False)
            self.image_sum_service = self.image_sum.get("service", "")
            self.image_sum_group = self.image_sum.get("group", True)
            self.image_sum_qa_prefix = self.image_sum.get("qa_prefix", "é—®")
            self.image_sum_prompt = self.image_sum.get("prompt", "")

            self.note_enabled = self.note.get("enabled", False)
            self.note_service = self.note.get("service", "")
            self.note_prefix = self.note.get("prefix", "è®°")

            # åˆå§‹åŒ–æˆåŠŸæ—¥å¿—
            logger.info("[sum4all] inited.")
            # Log configured services after initialization
            if self.url_sum_enabled:
                logger.info(f"[sum4all] URL Summarization ENABLED. Service: {self.url_sum_service}")
            else:
                logger.info("[sum4all] URL Summarization DISABLED.")
            
            if self.file_sum_enabled:
                logger.info(f"[sum4all] File Summarization ENABLED. Service: {self.file_sum_service}")
            else:
                logger.info("[sum4all] File Summarization DISABLED.")

            if self.image_sum_enabled:
                logger.info(f"[sum4all] Image Summarization ENABLED. Service: {self.image_sum_service}")
            else:
                logger.info("[sum4all] Image Summarization DISABLED.")
                
            if self.search_sum_enabled:
                 logger.info(f"[sum4all] Search Summarization ENABLED. Service: {self.search_sum_service}, Search Engine: {self.search_service}")
            else:
                 logger.info("[sum4all] Search Summarization DISABLED.")
                 
            if self.note_enabled:
                 logger.info(f"[sum4all] Note Taking ENABLED. Service: {self.note_service}")
            else:
                 logger.info("[sum4all] Note Taking DISABLED.")
                 
        except Exception as e:
            # åˆå§‹åŒ–å¤±è´¥æ—¥å¿—
            logger.warn(f"sum4all init failed: {e}")
    def on_handle_context(self, e_context: EventContext):
        context = e_context["context"]
        if context.type not in [ContextType.TEXT, ContextType.SHARING,ContextType.FILE,ContextType.IMAGE]:
            return
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        content = context.content
        isgroup = e_context["context"].get("isgroup", False)

        url_match = re.match('https?://(?:[-\w.]|(?:%[\da-fA-F]{2}))+', content)
        unsupported_urls = re.search(r'.*finder\.video\.qq\.com.*|.*support\.weixin\.qq\.com/update.*|.*support\.weixin\.qq\.com/security.*|.*mp\.weixin\.qq\.com/mp/waerrpage.*', content)

            # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä»¥"æœç´¢å‰ç¼€è¯" å¼€å¤´
        if content.startswith(self.search_sum_search_prefix) and self.search_sum_enabled:
            # å¦‚æœæ¶ˆæ¯æ¥è‡ªä¸€ä¸ªç¾¤èŠï¼Œå¹¶ä¸”ä½ ä¸å¸Œæœ›åœ¨ç¾¤èŠä¸­å¯ç”¨æœç´¢åŠŸèƒ½ï¼Œç›´æ¥è¿”å›
            if isgroup and not self.search_sum_group:
                return
            # Call new function to handle search operation
            self.call_service(content, e_context, "search")
            return
        
        if user_id in self.params_cache and ('last_file_content' in self.params_cache[user_id] or 'last_image_base64' in self.params_cache[user_id] or 'last_url' in self.params_cache[user_id]):
            # å¦‚æœå­˜åœ¨æœ€è¿‘ä¸€æ¬¡å¤„ç†çš„æ–‡ä»¶è·¯å¾„ï¼Œè§¦å‘æ–‡ä»¶ç†è§£å‡½æ•°
            if 'last_file_content' in self.params_cache[user_id] and content.startswith(self.file_sum_qa_prefix):
                logger.info('Content starts with the file_sum_qa_prefix.')
                # å»é™¤å…³é”®è¯å’Œç´§éšå…¶åçš„ç©ºæ ¼
                new_content = content[len(self.file_sum_qa_prefix):]
                self.params_cache[user_id]['prompt'] = new_content
                logger.info('params_cache for user has been successfully updated.')            
                self.handle_file(self.params_cache[user_id]['last_file_content'], e_context)
            # å¦‚æœå­˜åœ¨æœ€è¿‘ä¸€æ¬¡å¤„ç†çš„å›¾ç‰‡è·¯å¾„ï¼Œè§¦å‘å›¾ç‰‡ç†è§£å‡½æ•°
            elif 'last_image_base64' in self.params_cache[user_id] and content.startswith(self.image_sum_qa_prefix):
                logger.info('Content starts with the image_sum_qa_prefix.')
                # å»é™¤å…³é”®è¯å’Œç´§éšå…¶åçš„ç©ºæ ¼
                new_content = content[len(self.image_sum_qa_prefix):]
                self.params_cache[user_id]['prompt'] = new_content
                logger.info('params_cache for user has been successfully updated.')            
                self.handle_image(self.params_cache[user_id]['last_image_base64'], e_context)

            # å¦‚æœå­˜åœ¨æœ€è¿‘ä¸€æ¬¡å¤„ç†çš„URLï¼Œè§¦å‘URLç†è§£å‡½æ•°
            elif 'last_url' in self.params_cache[user_id] and content.startswith(self.url_sum_qa_prefix):
                logger.info('Content starts with the url_sum_qa_prefix.')
                # å»é™¤å…³é”®è¯å’Œç´§éšå…¶åçš„ç©ºæ ¼
                new_content = content[len(self.url_sum_qa_prefix):]
                self.params_cache[user_id]['prompt'] = new_content
                logger.info('params_cache for user has been successfully updated.')            
                self.call_service(self.params_cache[user_id]['last_url'], e_context ,"sum")
            elif 'last_url' in self.params_cache[user_id] and content.startswith(self.note_prefix) and self.note_enabled and not isgroup:
                logger.info('Content starts with the note_prefix.')
                new_content = content[len(self.note_prefix):]
                self.params_cache[user_id]['note'] = new_content
                logger.info('params_cache for user has been successfully updated.')  
                self.call_service(self.params_cache[user_id]['last_url'], e_context, "note")
        if context.type == ContextType.FILE:
            if isgroup and not self.file_sum_group:
                # ç¾¤èŠä¸­å¿½ç•¥å¤„ç†æ–‡ä»¶
                logger.info("ç¾¤èŠæ¶ˆæ¯ï¼Œæ–‡ä»¶å¤„ç†åŠŸèƒ½å·²ç¦ç”¨")
                return
            logger.info("on_handle_context: å¤„ç†ä¸Šä¸‹æ–‡å¼€å§‹")
            context.get("msg").prepare()
            file_path = context.content
            logger.info(f"on_handle_context: è·å–åˆ°æ–‡ä»¶è·¯å¾„ {file_path}")
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›è¡Œæ–‡ä»¶æ€»ç»“
            if self.file_sum_enabled:
                # æ›´æ–°params_cacheä¸­çš„last_file_content
                self.params_cache[user_id] = {}
                file_content = self.extract_content(file_path)
                if file_content is None:
                    logger.info("æ–‡ä»¶å†…å®¹æ— æ³•æå–ï¼Œè·³è¿‡å¤„ç†")
                else:
                    self.params_cache[user_id]['last_file_content'] = file_content
                    logger.info('Updated last_file_content in params_cache for user.')
                    self.handle_file(file_content, e_context)
            else:
                logger.info("æ–‡ä»¶æ€»ç»“åŠŸèƒ½å·²ç¦ç”¨ï¼Œä¸å¯¹æ–‡ä»¶å†…å®¹è¿›è¡Œå¤„ç†")
            # åˆ é™¤æ–‡ä»¶
            os.remove(file_path)
            logger.info(f"æ–‡ä»¶ {file_path} å·²åˆ é™¤")
        elif context.type == ContextType.IMAGE:
            if isgroup and not self.image_sum_group:
                # ç¾¤èŠä¸­å¿½ç•¥å¤„ç†å›¾ç‰‡
                logger.info("ç¾¤èŠæ¶ˆæ¯ï¼Œå›¾ç‰‡å¤„ç†åŠŸèƒ½å·²ç¦ç”¨")
                return
            logger.info("on_handle_context: å¼€å§‹å¤„ç†å›¾ç‰‡")
            context.get("msg").prepare()
            image_path = context.content
            logger.info(f"on_handle_context: è·å–åˆ°å›¾ç‰‡è·¯å¾„ {image_path}")
            
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›è¡Œå›¾ç‰‡æ€»ç»“
            if self.image_sum_enabled:
                # å°†å›¾ç‰‡è·¯å¾„è½¬æ¢ä¸ºBase64ç¼–ç çš„å­—ç¬¦ä¸²
                base64_image = self.encode_image_to_base64(image_path)
                # æ›´æ–°params_cacheä¸­çš„last_image_path
                self.params_cache[user_id] = {}
                self.params_cache[user_id]['last_image_base64'] = base64_image
                logger.info('Updated last_image_base64 in params_cache for user.')
                self.handle_image(base64_image, e_context)

            else:
                logger.info("å›¾ç‰‡æ€»ç»“åŠŸèƒ½å·²ç¦ç”¨ï¼Œä¸å¯¹å›¾ç‰‡å†…å®¹è¿›è¡Œå¤„ç†")
            # åˆ é™¤æ–‡ä»¶
            os.remove(image_path)
            logger.info(f"æ–‡ä»¶ {image_path} å·²åˆ é™¤")
        elif context.type == ContextType.SHARING and self.url_sum_enabled:  #åŒ¹é…å¡ç‰‡åˆ†äº«
            content = html.unescape(content)
            if unsupported_urls:  #åŒ¹é…ä¸æ”¯æŒæ€»ç»“çš„å¡ç‰‡
                if isgroup:  ##ç¾¤èŠä¸­å¿½ç•¥
                    return
                else:  ##ç§èŠå›å¤ä¸æ”¯æŒ
                    logger.info("[sum4all] Unsupported URL : %s", content)
                    reply = Reply(type=ReplyType.TEXT, content="ä¸æ”¯æŒæ€»ç»“å°ç¨‹åºå’Œè§†é¢‘å·")
                    e_context["reply"] = reply
                    e_context.action = EventAction.BREAK_PASS
            else:  #åŒ¹é…æ”¯æŒæ€»ç»“çš„å¡ç‰‡
                if isgroup:  #å¤„ç†ç¾¤èŠæ€»ç»“
                    if self.url_sum_group:  #group_sharing = Trueè¿›è¡Œæ€»ç»“ï¼ŒFalseåˆ™å¿½ç•¥ã€‚
                        logger.info("[sum4all] Summary URL : %s", content)
                        # æ›´æ–°params_cacheä¸­çš„last_url
                        self.params_cache[user_id] = {}
                        self.params_cache[user_id]['last_url'] = content
                        logger.info('Updated last_url in params_cache for user.')
                        # Add log before calling call_service
                        logger.info(f"[sum4all] Detected URL/Sharing (Group), preparing to call service for sum. Service configured: {self.url_sum_service}")
                        self.call_service(content, e_context, "sum")
                        return
                    else:
                        return
                else:  #å¤„ç†ç§èŠæ€»ç»“
                    logger.info("[sum4all] Summary URL : %s", content)
                    # æ›´æ–°params_cacheä¸­çš„last_url
                    self.params_cache[user_id] = {}
                    self.params_cache[user_id]['last_url'] = content
                    logger.info('Updated last_url in params_cache for user.')
                    # Add log before calling call_service
                    logger.info(f"[sum4all] Detected URL/Sharing (Private), preparing to call service for sum. Service configured: {self.url_sum_service}")
                    self.call_service(content, e_context, "sum")
                    return
            
        elif url_match and self.url_sum_enabled: #åŒ¹é…URLé“¾æ¥
            if unsupported_urls:  #åŒ¹é…ä¸æ”¯æŒæ€»ç»“çš„ç½‘å€
                logger.info("[sum4all] Unsupported URL : %s", content)
                reply = Reply(type=ReplyType.TEXT, content="ä¸æ”¯æŒæ€»ç»“å°ç¨‹åºå’Œè§†é¢‘å·")
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS
            else:
                logger.info("[sum4all] Summary URL : %s", content)
                # æ›´æ–°params_cacheä¸­çš„last_url
                self.params_cache[user_id] = {}
                self.params_cache[user_id]['last_url'] = content
                logger.info('Updated last_url in params_cache for user.')
                # Add log before calling call_service
                logger.info(f"[sum4all] Detected URL Match, preparing to call service for sum. Service configured: {self.url_sum_service}")
                self.call_service(content, e_context, "sum")
                return
    def call_service(self, content, e_context, service_type):
        # Add log at the beginning of call_service
        logger.info(f"[sum4all] Entering call_service for type '{service_type}'. Configured URL service: {self.url_sum_service}")
        if service_type == "search":
            if self.search_sum_service == "openai" or self.search_sum_service == "sum4all" or self.search_sum_service == "gemini" or self.search_sum_service == "azure":
                self.handle_search(content, e_context)
            elif self.search_sum_service == "perplexity":
                self.handle_perplexity(content, e_context)
        elif service_type == "sum":
            if self.url_sum_service == "bibigpt":
                self.handle_bibigpt(content, e_context)
            elif self.url_sum_service == "openai":
                self.handle_url(content, e_context)
            elif self.url_sum_service == "sum4all":
                self.handle_sum4all(content, e_context)
            elif self.url_sum_service == "gemini":
                self.handle_gemini(content, e_context)
            elif self.url_sum_service == "azure":
                self.handle_azure(content, e_context)
            elif self.url_sum_service == "opensum":
                self.handle_opensum(content, e_context)
            elif self.url_sum_service == "aliyun":
                self.handle_aliyun_url(content, e_context)
            elif self.url_sum_service == "sflow": # Existing elif for sflow
                self.handle_sflow_url(content, e_context) # Call the sflow handler
        elif service_type == "note":
            if self.note_service == "flomo":
                self.handle_note(content, e_context)
    def handle_note(self,link,e_context):
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        title = self.params_cache[user_id].get('title', '')
        content = self.params_cache[user_id].get('content', '')
        note = self.params_cache[user_id].get('note', '')
        # å°†è¿™äº›å†…å®¹æŒ‰ç…§ä¸€å®šçš„æ ¼å¼æ•´åˆåˆ°ä¸€èµ·
        note_content = f"#sum4all\n{title}\nğŸ“’ç¬”è®°ï¼š{note}\n{content}\n{link}"
        payload = {"content": note_content}
        # å°†è¿™ä¸ªå­—å…¸è½¬æ¢ä¸ºJSONæ ¼å¼
        payload_json = json.dumps(payload)
        # åˆ›å»ºä¸€ä¸ªPOSTè¯·æ±‚
        url = self.flomo_key
        headers = {'Content-Type': 'application/json'}
        # å‘é€è¿™ä¸ªPOSTè¯·æ±‚
        response = requests.post(url, headers=headers, data=payload_json)
        reply = Reply()
        reply.type = ReplyType.TEXT
        if response.status_code == 200 and response.json()['code'] == 0:
            reply.content = f"å·²å‘é€åˆ°{self.note_service}"        
        else:
            reply.content = "å‘é€å¤±è´¥ï¼Œé”™è¯¯ç ï¼š" + str(response.status_code)
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS   
    def short_url(self, long_url):
        url = "https://short.fatwang2.com"
        payload = {
            "url": long_url
        }        
        headers = {'Content-Type': "application/json"}
        response = requests.request("POST", url, json=payload, headers=headers)
        if response.status_code == 200:
            res_data = response.json()
            # ç›´æ¥ä»è¿”å›çš„ JSON ä¸­è·å–çŸ­é“¾æ¥
            short_url = res_data.get('shorturl', None)  
            
            if short_url:
                return short_url
        return None
    def get_webpage_content(self, url):
        """è·å–ç½‘é¡µå†…å®¹"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Cache-Control': 'max-age=0'
            }

            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            logger.debug(f"Checking URL for weixin: url='{url}', contains_weixin={'weixin.qq.com' in url}")
            # ä¿®æ”¹åˆ¤æ–­æ ‡å‡†ï¼šæ£€æŸ¥URLæ˜¯å¦åŒ…å« weixin.qq.com
            if "weixin.qq.com" in url:
                logger.info(f"æ£€æµ‹åˆ°å¾®ä¿¡ç›¸å…³åŸŸåï¼Œå°è¯•ç›´æ¥è·å–å†…å®¹: {url}")
                # æ›´æ–°è¯·æ±‚å¤´ï¼ŒåŠ å…¥ Referer
                headers['Referer'] = 'https://mp.weixin.qq.com/' # Referer ä¿æŒ mp.
                response = requests.get(url, headers=headers, verify=False, timeout=15)
                response.raise_for_status()
                # è®°å½•å“åº”å¤´ä¸­çš„ Content-Type
                content_type_header = response.headers.get('Content-Type')
                logger.debug(f"Response Content-Type header: {content_type_header}")
                # ç§»é™¤ apparent_encoding çš„çŒœæµ‹ï¼Œå¼ºåˆ¶ä½¿ç”¨ UTF-8
                # response.encoding = response.apparent_encoding 
                html_content_bytes = response.content
                html_text = html_content_bytes.decode('utf-8', errors='replace')
                # è®°å½•è§£ç åçš„repr
                logger.debug(f"Decoded html_text (repr): {repr(html_text[:500])}...")
                
                # ä½¿ç”¨å¼ºåˆ¶è§£ç åçš„æ–‡æœ¬è¿›è¡Œè§£æ
                soup = BeautifulSoup(html_text, 'html.parser')
                
                # æŸ¥æ‰¾æ ‡é¢˜ (å¯é€‰, ä¸»è¦ç”¨äºè°ƒè¯•)
                title_tag = soup.find('h1', class_='rich_media_title') or \
                            soup.find('h1', id='activity-name')
                if title_tag:
                    logger.info(f"å¾®ä¿¡æ–‡ç« æ ‡é¢˜: {title_tag.get_text(strip=True)}")
                    extracted_title = title_tag.get_text(strip=True)
                else:
                    logger.warning("æœªæ‰¾åˆ°å¾®ä¿¡æ–‡ç« æ ‡é¢˜æ ‡ç­¾")
                    extracted_title = None

                # æŸ¥æ‰¾æ­£æ–‡ï¼Œä¼˜å…ˆ rich_media_content
                content_tag = soup.find('div', class_='rich_media_content') or \
                             soup.find('div', id='js_content')
                             
                if content_tag:
                    # æ¸…ç†ä¸éœ€è¦çš„æ ‡ç­¾
                    for element in content_tag(['script', 'style', 'iframe', 'img', 'video']):
                        element.decompose()
                    # æå–æ¸…ç†åçš„æ–‡æœ¬
                    text = content_tag.get_text(separator='\n', strip=True)
                    logger.info("å¾®ä¿¡å…¬ä¼—å·å†…å®¹è·å–å¹¶æ¸…ç†æˆåŠŸ")
                    # è®°å½• get_text åçš„ repr
                    logger.debug(f"Text after get_text (repr): {repr(text[:500])}...")
                else:
                    logger.error("æ— æ³•ä»å¾®ä¿¡å…¬ä¼—å·é¡µé¢æå–æ­£æ–‡å†…å®¹ (rich_media_content æˆ– js_content)")
                    return None, None # è¿”å› None å†…å®¹å’Œ None æ ‡é¢˜
            else:
                # ä½¿ç”¨jina.aié¢„å¤„ç†URL
                jina_url = f"https://r.jina.ai/{url}"
                logger.info(f"éå¾®ä¿¡åŸŸåï¼Œä½¿ç”¨jina.aié¢„å¤„ç†URL: {jina_url}")
                
                # è·å–jina.aiå¤„ç†åçš„å†…å®¹
                response = requests.get(jina_url, headers=headers, verify=False, timeout=20) # å¢åŠ è¶…æ—¶
                response.raise_for_status()
                # Jina è¿”å›çš„æ˜¯çº¯æ–‡æœ¬ï¼Œç›´æ¥ä½¿ç”¨
                text = response.text
                logger.info("jina.ai å†…å®¹è·å–æˆåŠŸ")

            # --- é€šç”¨æ–‡æœ¬æ¸…ç†é€»è¾‘ ---
            # 1. ç§»é™¤URLé“¾æ¥ (ä¿ç•™å¾®ä¿¡çš„æ¸…ç†é€»è¾‘ï¼Œä½†å¯¹Jinaå¯èƒ½ä¸éœ€è¦)
            if "weixin.qq.com" not in url:
                 text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)

            # 2. ç§»é™¤é‚®ç®±åœ°å€
            text = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', '', text)

            # 3. ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œ (ä¿ç•™ï¼Œå¯¹ä¸¤è€…éƒ½æœ‰ç”¨)
            text = re.sub(r'\\s+', ' ', text)
            text = text.replace('\\n', ' ') # å°†æ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œé¿å…è¿‡å¤šç©ºè¡Œ

            # 4. ç§»é™¤ç‰¹æ®Šå­—ç¬¦ (ä¿ç•™ï¼Œä½†å¯¹ä¸­æ–‡å†…å®¹å¯èƒ½è¿‡äºæ¿€è¿›ï¼Œç¨ä½œè°ƒæ•´)
            # text = re.sub(r'[^\w\s\u4e00-\u9fff.,!?ï¼Œã€‚ï¼ï¼Ÿ]', '', text) # åŸé€»è¾‘
            # ä¿®æ­£Linteré”™è¯¯ï¼š
            text = re.sub(r'[^\w\s\u4e00-\u9fff,.!?;:"ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š"()"ï¼ˆï¼‰ã€Šã€‹ã€ã€‘ã€Œã€ï¿¥$@%#&*_=+`~^<>|\/\[\]{}-]', '', text) # ç»Ÿä¸€å¼•å·å¹¶ç¡®ä¿æ‹¬å·é—­åˆ

            # 5. ç§»é™¤æ•°å­—ç¼–å· (ä¿ç•™)
            text = re.sub(r'^\d+\.\s*', '', text, flags=re.MULTILINE)

            # 6. ç§»é™¤é‡å¤çš„æ ‡ç‚¹ç¬¦å· (ä¿ç•™)
            text = re.sub(r'([.,!?ï¼Œã€‚ï¼ï¼Ÿ])\\1+', r'\\1', text)

            # 7. ç§»é™¤å¤šä½™ç©ºè¡Œ (è°ƒæ•´é€»è¾‘ï¼Œå…ˆåˆå¹¶ç©ºæ ¼å†å¤„ç†)
            text = re.sub(r' {2,}', ' ', text) # åˆå¹¶å¤šä¸ªç©ºæ ¼
            text = text.strip() # ç§»é™¤é¦–å°¾ç©ºæ ¼

            # 8. ç§»é™¤è¡Œé¦–è¡Œå°¾çš„ç©ºç™½ (å·²é€šè¿‡ strip å¤„ç†)

            # å¦‚æœå†…å®¹å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯æ²¡æœ‰æ­£ç¡®è·å–
            if len(text) < 50:
                logger.warning("è·å–åˆ°çš„å†…å®¹å¤ªçŸ­ï¼Œå¯èƒ½æœªæ­£ç¡®è·å–æ–‡ç« å†…å®¹")
                return None, None # è¿”å› None å†…å®¹å’Œ None æ ‡é¢˜
            
            # è®°å½•æœ€ç»ˆè¿”å›å‰çš„ repr
            logger.debug(f"Final text before return (repr): {repr(text[:500])}...")
            # å¦‚æœæ˜¯ Jina è·¯å¾„ï¼Œå°è¯•æå–æ ‡é¢˜
            if "weixin.qq.com" not in url:
                lines = text.split('\n')
                extracted_title = next((line.strip() for line in lines if line.strip()), None)
            # å¦åˆ™ extracted_title å·²åœ¨å¾®ä¿¡è·¯å¾„ä¸­è®¾ç½®
            logger.debug(f"Extracted title before return: {extracted_title}")
            return text, extracted_title
                
        except Exception as e:
            logger.error(f"è·å–ç½‘é¡µå†…å®¹æ—¶å‡ºé”™: {e}")
            return None, None # å¼‚å¸¸ä¹Ÿè¿”å› None, None

    def handle_url(self, content, e_context):
        logger.info('Handling OpenAI request...')
        # åªå¤„ç† OpenAI æœåŠ¡
        if self.url_sum_service != "openai":
            logger.error(f"å½“å‰é…ç½®çš„æœåŠ¡ä¸æ˜¯ OpenAI: {self.url_sum_service}")
            return
            
        api_key = self.open_ai_api_key
        # ä¿®æ”¹APIåŸºç¡€URLçš„æ ¼å¼ï¼Œç¡®ä¿ä½¿ç”¨httpè€Œä¸æ˜¯https
        api_base = self.open_ai_api_base.replace('https://', 'http://')
        model = self.model
        
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        user_params = self.params_cache.get(user_id, {})
        prompt = user_params.get('prompt', self.url_sum_prompt)
        
        # è·å–ç½‘é¡µå†…å®¹
        webpage_content = self.get_webpage_content(content)
        if not webpage_content:
            reply_content = "æ— æ³•è·å–ç½‘é¡µå†…å®¹ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆ"
        else:
            # æ„å»º OpenAI API è¯·æ±‚
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {api_key}'
            }
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç½‘é¡µå†…å®¹æ€»ç»“ä¸“å®¶ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ€»ç»“ç½‘é¡µå†…å®¹ï¼š
1. é¦–å…ˆç”¨ä¸€å¥è¯æ€»ç»“æ–‡ç« çš„æ ¸å¿ƒè§‚ç‚¹ï¼ˆ30å­—ä»¥å†…ï¼‰
2. ç„¶ååˆ—å‡º3-5ä¸ªå…³é”®è¦ç‚¹
3. ä½¿ç”¨emojiè®©è¡¨è¾¾æ›´ç”ŸåŠ¨
4. ä¿æŒä¸“ä¸šã€å®¢è§‚çš„è¯­æ°”"""

            # æ„å»ºç”¨æˆ·æç¤ºè¯
            user_prompt = f"""è¯·æ€»ç»“ä»¥ä¸‹ç½‘é¡µå†…å®¹ï¼š
{prompt}

ç½‘é¡µå†…å®¹ï¼š
{webpage_content[:4000]}  # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…è¶…å‡ºtokené™åˆ¶"""

            # æ„å»ºè¯·æ±‚ä½“
            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1000
            }

            additional_content = ""
            try:
                logger.info('Sending request to OpenAI...')
                # ç›´æ¥è°ƒç”¨ OpenAI APIï¼Œç¦ç”¨SSLéªŒè¯
                response = requests.post(
                    f"{api_base}/chat/completions",
                    headers=headers,
                    json=payload,
                    verify=False  # ç¦ç”¨SSLéªŒè¯
                )
                response.raise_for_status()
                logger.info('Received response from OpenAI.')
                
                response_data = response.json()
                if "choices" in response_data and len(response_data["choices"]) > 0:
                    content = response_data["choices"][0]["message"]["content"]
                    self.params_cache[user_id]['content'] = content
                    
                    # å°è¯•ä»å†…å®¹ä¸­æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œï¼‰
                    lines = content.split('\n')
                    if lines:
                        title = lines[0].strip()
                        self.params_cache[user_id]['title'] = title
                        if title:
                            additional_content += f"{title}\n\n"
                    
                    reply_content = additional_content + content
                else:
                    reply_content = "æ— æ³•è·å–æœ‰æ•ˆçš„å“åº”å†…å®¹"

            except requests.exceptions.RequestException as e:
                logger.error(f"Error calling OpenAI API: {e}")
                reply_content = f"è°ƒç”¨ OpenAI API æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

        reply = Reply()
        reply.type = ReplyType.TEXT
        if not self.url_sum_qa_enabled:
            reply.content = remove_markdown(reply_content)
        elif isgroup or not self.note_enabled:
            reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.url_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®"
        elif self.note_enabled:
            reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.url_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®\nğŸ’¡è¾“å…¥{self.note_prefix}+ç¬”è®°ï¼Œå¯ä¿å­˜åˆ°{self.note_service}"
        
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def handle_bibigpt(self, content, e_context):    
        headers = {
            'Content-Type': 'application/json'
        }
        payload_params = {
            "url": content,
            "includeDetail": False,
            "promptConfig": {
                "outputLanguage": self.outputLanguage
            }
        }

        payload = json.dumps(payload_params)           
        try:
            api_url = f"https://bibigpt.co/api/open/{self.bibigpt_key}"
            response = requests.request("POST",api_url, headers=headers, data=payload)
            response.raise_for_status()
            data = json.loads(response.text)
            summary_original = data.get('summary', 'Summary not available')
            html_url = data.get('htmlUrl', 'HTML URL not available')
            # è·å–çŸ­é“¾æ¥
            short_url = self.short_url(html_url) 
            
            # å¦‚æœè·å–çŸ­é“¾æ¥å¤±è´¥ï¼Œä½¿ç”¨ html_url
            if short_url is None:
                short_url = html_url if html_url != 'HTML URL not available' else 'URL not available'
            
            # ç§»é™¤ "##æ‘˜è¦"ã€"## äº®ç‚¹" å’Œ "-"
            summary = summary_original.split("è¯¦ç»†ç‰ˆï¼ˆæ”¯æŒå¯¹è¯è¿½é—®ï¼‰")[0].replace("## æ‘˜è¦\n", "ğŸ“Œæ€»ç»“ï¼š").replace("## äº®ç‚¹\n", "").replace("- ", "")
        except requests.exceptions.RequestException as e:
            reply = f"An error occurred"

        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{summary}\n\nè¯¦ç»†é“¾æ¥ï¼š{short_url}"

        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def handle_opensum(self, content, e_context):
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.opensum_key}'
        }
        payload = json.dumps({"link": content})
        try:
            api_url = "https://read.thinkwx.com/api/v1/article/summary"
            response = requests.request("POST",api_url, headers=headers, data=payload)
            response.raise_for_status()
            data = json.loads(response.text)
            summary_data = data.get('data', {})  # è·å–dataå­—æ®µ                
            summary_original = summary_data.get('summary', 'Summary not available')
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–URL
            url_pattern = r'https:\/\/[^\s]+'
            match = re.search(url_pattern, summary_original)
            html_url = match.group(0) if match else 'HTML URL not available'            
            # è·å–çŸ­é“¾æ¥
            short_url = self.short_url(html_url) if match else html_url
            # ç”¨äºç§»é™¤æ‘˜è¦ä¸­çš„URLåŠå…¶åçš„æ‰€æœ‰å†…å®¹
            url_pattern_remove = r'https:\/\/[^\s]+[\s\S]*'
            summary = re.sub(url_pattern_remove, '', summary_original).strip()        

        except requests.exceptions.RequestException as e:
            summary = f"An error occurred"
            short_url = 'URL not available'
        
        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{summary}\n\nè¯¦ç»†é“¾æ¥ï¼š{short_url}"

        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS    
    def handle_search(self, content, e_context):
        # æ ¹æ®sum_serviceçš„å€¼é€‰æ‹©APIå¯†é’¥å’ŒåŸºç¡€URL
        if self.search_sum_service == "openai":
            api_key = self.open_ai_api_key
            api_base = self.open_ai_api_base
            model = self.model
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {api_key}'
            }
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœç´¢ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä»æœç´¢ç»“æœä¸­æå–ç›¸å…³ä¿¡æ¯ï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
1. é¦–å…ˆç”¨ä¸€å¥è¯æ€»ç»“ç­”æ¡ˆçš„æ ¸å¿ƒè§‚ç‚¹ï¼ˆ30å­—ä»¥å†…ï¼‰
2. ç„¶ååˆ—å‡º3-5ä¸ªå…³é”®è¦ç‚¹
3. ä½¿ç”¨emojiè®©è¡¨è¾¾æ›´ç”ŸåŠ¨
4. ä¿æŒä¸“ä¸šã€å®¢è§‚çš„è¯­æ°”"""

            # æ„å»ºç”¨æˆ·æç¤ºè¯
            user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹é—®é¢˜æœç´¢å¹¶æ€»ç»“ï¼š
{content[len(self.search_sum_search_prefix):]}

æœç´¢æœåŠ¡ï¼š{self.search_service}"""

            # æ„å»ºè¯·æ±‚ä½“
            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1000
            }

            try:
                response = requests.post(
                    f"{api_base}/chat/completions",
                    headers=headers,
                    json=payload
                )
                response.raise_for_status()
                response_data = response.json()
                
                if "choices" in response_data and len(response_data["choices"]) > 0:
                    reply_content = response_data["choices"][0]["message"]["content"]
                else:
                    reply_content = "æ— æ³•è·å–æœ‰æ•ˆçš„å“åº”å†…å®¹"

            except requests.exceptions.RequestException as e:
                logger.error(f"Error calling OpenAI API: {e}")
                reply_content = f"è°ƒç”¨ OpenAI API æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

        elif self.search_sum_service == "sum4all":
            api_key = self.sum4all_key
            api_base = "https://pro.sum4all.site/v1"
            model = "sum4all"
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {api_key}'
            }
            payload = {
                "ur": content[len(self.search_sum_search_prefix):],
                "prompt": self.search_sum_prompt,
                "model": model,
                "base": api_base,
                "search1api_key": self.search1api_key,
                "search_service": self.search_service
            }
            try:
                response = requests.post(api_base, headers=headers, json=payload)
                response.raise_for_status()
                response_data = response.json()
                if response_data.get("success"):
                    reply_content = response_data["content"].replace("\\n", "\n")
                else:
                    reply_content = "æ— æ³•è·å–æœ‰æ•ˆçš„å“åº”å†…å®¹"
            except requests.exceptions.RequestException as e:
                logger.error(f"Error calling Sum4All API: {e}")
                reply_content = f"è°ƒç”¨ Sum4All API æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

        elif self.search_sum_service == "gemini":
            api_key = self.gemini_key
            model = "gemini"
            api_base = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
            headers = {
                'Content-Type': 'application/json',
                'x-goog-api-key': api_key
            }
            
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœç´¢ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä»æœç´¢ç»“æœä¸­æå–ç›¸å…³ä¿¡æ¯ï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
1. é¦–å…ˆç”¨ä¸€å¥è¯æ€»ç»“ç­”æ¡ˆçš„æ ¸å¿ƒè§‚ç‚¹ï¼ˆ30å­—ä»¥å†…ï¼‰
2. ç„¶ååˆ—å‡º3-5ä¸ªå…³é”®è¦ç‚¹
3. ä½¿ç”¨emojiè®©è¡¨è¾¾æ›´ç”ŸåŠ¨
4. ä¿æŒä¸“ä¸šã€å®¢è§‚çš„è¯­æ°”"""

            user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹é—®é¢˜æœç´¢å¹¶æ€»ç»“ï¼š
{content[len(self.search_sum_search_prefix):]}

æœç´¢æœåŠ¡ï¼š{self.search_service}"""

            payload = {
                "contents": [
                    {"role": "user", "parts": [{"text": system_prompt}]},
                    {"role": "model", "parts": [{"text": "okay"}]},
                    {"role": "user", "parts": [{"text": user_prompt}]}
                ],
                "generationConfig": {
                    "maxOutputTokens": 800
                }
            }

            try:
                response = requests.post(api_base, headers=headers, json=payload)
                response.raise_for_status()
                response_data = response.json()
                
                if "candidates" in response_data and len(response_data["candidates"]) > 0:
                    reply_content = response_data["candidates"][0]["content"]["parts"][0]["text"]
                else:
                    reply_content = "æ— æ³•è·å–æœ‰æ•ˆçš„å“åº”å†…å®¹"

            except requests.exceptions.RequestException as e:
                logger.error(f"Error calling Gemini API: {e}")
                reply_content = f"è°ƒç”¨ Gemini API æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

        elif self.search_sum_service == "azure":
            api_key = self.open_ai_api_key
            api_base = f"{self.open_ai_api_base}/openai/deployments/{self.azure_deployment_id}/chat/completions?api-version=2024-02-15-preview"
            model = self.model
            headers = {
                'Content-Type': 'application/json',
                'api-key': api_key
            }
            
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœç´¢ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä»æœç´¢ç»“æœä¸­æå–ç›¸å…³ä¿¡æ¯ï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
1. é¦–å…ˆç”¨ä¸€å¥è¯æ€»ç»“ç­”æ¡ˆçš„æ ¸å¿ƒè§‚ç‚¹ï¼ˆ30å­—ä»¥å†…ï¼‰
2. ç„¶ååˆ—å‡º3-5ä¸ªå…³é”®è¦ç‚¹
3. ä½¿ç”¨emojiè®©è¡¨è¾¾æ›´ç”ŸåŠ¨
4. ä¿æŒä¸“ä¸šã€å®¢è§‚çš„è¯­æ°”"""

            user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹é—®é¢˜æœç´¢å¹¶æ€»ç»“ï¼š
{content[len(self.search_sum_search_prefix):]}

æœç´¢æœåŠ¡ï¼š{self.search_service}"""

            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            }

            try:
                response = requests.post(api_base, headers=headers, json=payload)
                response.raise_for_status()
                response_data = response.json()
                
                if "choices" in response_data and len(response_data["choices"]) > 0:
                    reply_content = response_data["choices"][0]["message"]["content"]
                else:
                    reply_content = "æ— æ³•è·å–æœ‰æ•ˆçš„å“åº”å†…å®¹"

            except requests.exceptions.RequestException as e:
                logger.error(f"Error calling Azure API: {e}")
                reply_content = f"è°ƒç”¨ Azure API æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

        else:
            logger.error(f"æœªçŸ¥çš„search_serviceé…ç½®: {self.search_sum_service}")
            return

        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{remove_markdown(reply_content)}"            
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def handle_perplexity(self, content, e_context):

        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.perplexity_key}'
        }
        data = {
            "model": "sonar-small-online",
            "messages": [
                {"role": "system", "content": self.search_sum_prompt},
                {"role": "user", "content": content}
        ]
        }
        try:
            api_url = "https://api.perplexity.ai/chat/completions"
            response = requests.post(api_url, headers=headers, json=data)
            response.raise_for_status()
            # å¤„ç†å“åº”æ•°æ®
            response_data = response.json()
            # è¿™é‡Œå¯ä»¥æ ¹æ®ä½ çš„éœ€è¦å¤„ç†å“åº”æ•°æ®
            # è§£æ JSON å¹¶è·å– content
            if "choices" in response_data and len(response_data["choices"]) > 0:
                first_choice = response_data["choices"][0]
                if "message" in first_choice and "content" in first_choice["message"]:
                    content = first_choice["message"]["content"]
                else:
                    print("Content not found in the response")
            else:
                print("No choices available in the response")
        except requests.exceptions.RequestException as e:
            # å¤„ç†å¯èƒ½å‡ºç°çš„é”™è¯¯
            logger.error(f"Error calling perplexity: {e}")
        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{remove_markdown(content)}"            
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def get_help_text(self, verbose=False, **kwargs):
        help_text = "Help you summarize all things\n"
        if not verbose:
            return help_text
        help_text += "1.Share me the link and I will summarize it for you\n"
        help_text += f"2.{self.search_sum_search_prefix}+query,I will search online for you\n"
        return help_text
    def handle_file(self, content, e_context):
        logger.info("handle_file: å‘LLMå‘é€å†…å®¹æ€»ç»“è¯·æ±‚")
        # æ ¹æ®sum_serviceçš„å€¼é€‰æ‹©APIå¯†é’¥å’ŒåŸºç¡€URL
        if self.file_sum_service == "openai":
            api_key = self.open_ai_api_key
            api_base = self.open_ai_api_base
            model = self.model
        elif self.file_sum_service == "azure":
            api_key = self.open_ai_api_key
            api_base = f"{self.open_ai_api_base}/openai/deployments/{self.azure_deployment_id}/chat/completions?api-version=2024-02-15-preview"
            model = self.model
        elif self.file_sum_service == "sum4all":
            api_key = self.sum4all_key
            api_base = "https://pro.sum4all.site/v1"
            model = "sum4all"
        elif self.file_sum_service == "gemini":
            api_key = self.gemini_key
            model = "gemini"
            api_base = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
        elif self.file_sum_service == "aliyun":
            reply_content = self.handle_aliyun_file(content, e_context)
            
            reply = Reply()
            reply.type = ReplyType.TEXT
            reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.file_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®" 
            e_context["reply"] = reply
            e_context.action = EventAction.BREAK_PASS
            return
        else:
            logger.error(f"æœªçŸ¥çš„sum_serviceé…ç½®: {self.file_sum_service}")
            return
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        user_params = self.params_cache.get(user_id, {})
        prompt = user_params.get('prompt', self.file_sum_prompt)
        if model == "gemini":
            headers = {
                'Content-Type': 'application/json',
                'x-goog-api-key': api_key
            }
            data = {
            "contents": [
                {"role": "user", "parts": [{"text": prompt}]},
                {"role": "model", "parts": [{"text": "okay"}]},
                {"role": "user", "parts": [{"text": content}]}
            ],
            "generationConfig": {
                "maxOutputTokens": 800
            }
            }
            api_url = api_base
        elif self.file_sum_service == "azure":
            headers = {
                "Content-Type": "application/json",
                "api-key": api_key
            }
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": content}
                ]
            }
            api_url = api_base
        elif self.file_sum_service == "aliyun":
            api_key = self.aliyun_key
            model = "aliyun"
            api_base = self.aliyun_base_url
            
            if has_openai:
                # ä½¿ç”¨OpenAIå®¢æˆ·ç«¯åº“
                try:
                    logger.info(f"ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è°ƒç”¨é˜¿é‡Œäº‘API: {api_base}")
                    client = OpenAI(
                        api_key=api_key,
                        base_url=api_base
                    )
                    
                    completion = client.chat.completions.create(
                        model=self.aliyun_sum_model,
                        messages=[
                            {"role": "system", "content": prompt},
                            {"role": "user", "content": content}
                        ],
                        temperature=0.7,
                        max_tokens=2000
                    )
                    
                    logger.info("OpenAIå®¢æˆ·ç«¯æˆåŠŸè·å–å“åº”")
                    response_content = completion.choices[0].message.content.strip()
                    return response_content.replace("\\n", "\n")
                    
                except Exception as e:
                    logger.error(f"ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è°ƒç”¨é˜¿é‡Œäº‘APIå‡ºé”™: {e}")
                    logger.info("è½¬ä¸ºä½¿ç”¨requestsç›´æ¥è°ƒç”¨")
            
            # ä½¿ç”¨requestsç›´æ¥è°ƒç”¨
            try:
                logger.info("ä½¿ç”¨requestsç›´æ¥è°ƒç”¨é˜¿é‡Œäº‘API")
                headers = {
                    'Content-Type': 'application/json',
                    'Authorization': f'Bearer {api_key}'
                }
                
                data = {
                    "model": self.aliyun_sum_model,
                    "messages": [
                        {"role": "system", "content": prompt},
                        {"role": "user", "content": content}
                    ],
                    "temperature": 0.7,
                    "max_tokens": 2000
                }
                
                api_url = api_base if "/chat/completions" in api_base else f"{api_base}/chat/completions"
                logger.info(f"è¯·æ±‚URL: {api_url}")
                
                response = requests.post(
                    api_url,
                    headers=headers,
                    json=data,
                    verify=False,
                    timeout=30
                )
                
                response.raise_for_status()
                logger.info(f"APIå“åº”çŠ¶æ€ç : {response.status_code}")
                
                response_data = response.json()
                if "choices" in response_data and len(response_data["choices"]) > 0:
                    first_choice = response_data["choices"][0]
                    if "message" in first_choice and "content" in first_choice["message"]:
                        response_content = first_choice["message"]["content"].strip()
                        logger.info("æˆåŠŸè·å–é˜¿é‡Œäº‘APIå“åº”å†…å®¹")
                        return response_content.replace("\\n", "\n")
                    else:
                        logger.error("é˜¿é‡Œäº‘APIå“åº”ä¸­æœªæ‰¾åˆ°å†…å®¹å­—æ®µ")
                        return "æœªèƒ½ä»é˜¿é‡Œäº‘APIè·å–æœ‰æ•ˆçš„å“åº”å†…å®¹"
                else:
                    logger.error("é˜¿é‡Œäº‘APIå“åº”ä¸­æœªæ‰¾åˆ°choiceså­—æ®µ")
                    return "æœªèƒ½ä»é˜¿é‡Œäº‘APIè·å–æœ‰æ•ˆçš„å“åº”å†…å®¹"
                    
            except Exception as e:
                logger.error(f"è°ƒç”¨é˜¿é‡Œäº‘APIæ—¶å‡ºé”™: {e}")
                if hasattr(e, 'response') and e.response:
                    logger.error(f"å“åº”çŠ¶æ€ç : {e.response.status_code}")
                    logger.error(f"å“åº”å†…å®¹: {e.response.text}")
                return f"è°ƒç”¨é˜¿é‡Œäº‘APIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        else:
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {api_key}'
            }
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": content}
                ]
            }
            api_url = f"{api_base}/chat/completions"
        try:
            response = requests.post(api_url, headers=headers, data=json.dumps(data))
            response.raise_for_status()
            response_data = response.json()
            
            # è§£æ JSON å¹¶è·å– content
            if model == "gemini":
                if "candidates" in response_data and len(response_data["candidates"]) > 0:
                    first_candidate = response_data["candidates"][0]
                    if "content" in first_candidate:
                        if "parts" in first_candidate["content"] and len(first_candidate["content"]["parts"]) > 0:
                            response_content = first_candidate["content"]["parts"][0]["text"].strip()  # è·å–å“åº”å†…å®¹
                            logger.info(f"Gemini API response content: {response_content}")  # è®°å½•å“åº”å†…å®¹
                            reply_content = response_content.replace("\\n", "\n")  # æ›¿æ¢ \\n ä¸º \n
                        else:
                            logger.error("Parts not found in the Gemini API response content")
                            reply_content = "Parts not found in the Gemini API response content"
                    else:
                        logger.error("Content not found in the Gemini API response candidate")
                        reply_content = "Content not found in the Gemini API response candidate"
                else:
                    logger.error("No candidates available in the Gemini API response")
                    reply_content = "No candidates available in the Gemini API response"        
            else:
                if "choices" in response_data and len(response_data["choices"]) > 0:
                    first_choice = response_data["choices"][0]
                    if "message" in first_choice and "content" in first_choice["message"]:
                        response_content = first_choice["message"]["content"].strip()
                        logger.info(f"LLM API response content")  # è®°å½•å“åº”å†…å®¹
                        reply_content = response_content.replace("\\n", "\n")  # æ›¿æ¢ \\n ä¸º \n
                    else:
                        logger.error("Content not found in the response")
                        reply_content = "Content not found in the LLM API response"
                else:
                    logger.error("No choices available in the response")
                    reply_content = "No choices available in the LLM API response"

        except requests.exceptions.RequestException as e:
            logger.error(f"Error calling LLM API: {e}")
            reply_content = f"An error occurred while calling LLM API"

        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.file_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®" 
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def read_pdf(self, file_path):
        logger.info(f"å¼€å§‹è¯»å–PDFæ–‡ä»¶ï¼š{file_path}")
        doc = fitz.open(file_path)
        content = ' '.join([page.get_text() for page in doc])
        logger.info(f"PDFæ–‡ä»¶è¯»å–å®Œæˆï¼š{file_path}")

        return content
    def read_word(self, file_path):
        doc = Document(file_path)
        return ' '.join([p.text for p in doc.paragraphs])
    def read_markdown(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as file:
            md_content = file.read()
            return markdown.markdown(md_content)
    def read_excel(self, file_path):
        workbook = load_workbook(file_path)
        content = ''
        for sheet in workbook:
            for row in sheet.iter_rows():
                content += ' '.join([str(cell.value) for cell in row])
                content += '\n'
        return content
    def read_txt(self, file_path):
        logger.debug(f"å¼€å§‹è¯»å–TXTæ–‡ä»¶: {file_path}")
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            logger.debug(f"TXTæ–‡ä»¶è¯»å–å®Œæˆ: {file_path}")
            logger.debug("TXTæ–‡ä»¶å†…å®¹çš„å‰50ä¸ªå­—ç¬¦ï¼š")
            logger.debug(content[:50])  # æ‰“å°æ–‡ä»¶å†…å®¹çš„å‰50ä¸ªå­—ç¬¦
            return content
        except Exception as e:
            logger.error(f"è¯»å–TXTæ–‡ä»¶æ—¶å‡ºé”™: {file_path}ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}")
            return ""
    def read_csv(self, file_path):
        content = ''
        with open(file_path, 'r', encoding='utf-8') as csvfile:
            reader = csv.reader(csvfile)
            for row in reader:
                content += ' '.join(row) + '\n'
        return content
    def read_html(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as file:
            soup = BeautifulSoup(file, 'html.parser')
            return soup.get_text()
    def read_ppt(self, file_path):
        presentation = Presentation(file_path)
        content = ''
        for slide in presentation.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    content += shape.text + '\n'
        return content
    def extract_content(self, file_path):
        logger.info(f"extract_content: æå–æ–‡ä»¶å†…å®¹ï¼Œæ–‡ä»¶è·¯å¾„: {file_path}")
        file_size = os.path.getsize(file_path) // 1000  # å°†æ–‡ä»¶å¤§å°è½¬æ¢ä¸ºKB
        if file_size > int(self.max_file_size):
            logger.warning(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶({self.max_file_size}KB),ä¸è¿›è¡Œå¤„ç†ã€‚æ–‡ä»¶å¤§å°: {file_size}KB")
            return None
        file_extension = os.path.splitext(file_path)[1][1:].lower()
        logger.info(f"extract_content: æ–‡ä»¶ç±»å‹ä¸º {file_extension}")

        file_type = EXTENSION_TO_TYPE.get(file_extension)

        if not file_type:
            logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å: {file_extension}")
            return None

        read_func = {
            'pdf': self.read_pdf,
            'docx': self.read_word,
            'md': self.read_markdown,
            'txt': self.read_txt,
            'excel': self.read_excel,
            'csv': self.read_csv,
            'html': self.read_html,
            'ppt': self.read_ppt
        }.get(file_type)

        if not read_func:
            logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")
            return None
        logger.info("extract_content: æ–‡ä»¶å†…å®¹æå–å®Œæˆ")
        return read_func(file_path)
    def encode_image_to_base64(self, image_path):
        # æ‰“å¼€å›¾ç‰‡
        img = Image.open(image_path)
        # åªæœ‰å½“å›¾ç‰‡çš„å®½åº¦å¤§äº1024åƒç´ æ—¶ï¼Œæ‰è°ƒæ•´å›¾ç‰‡å¤§å°
        if img.width > 1024:
            img = img.resize((1024, int(img.height*1024/img.width)))
            # å°†è°ƒæ•´å¤§å°åçš„å›¾ç‰‡ä¿å­˜å›åŸæ–‡ä»¶
            img.save(image_path)

        # æ‰“å¼€è°ƒæ•´å¤§å°åçš„å›¾ç‰‡ï¼Œè¯»å–å¹¶è¿›è¡Œbase64ç¼–ç 
        with open(image_path, "rb") as image_file:
            encoded = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded
    def handle_image(self, base64_image, e_context):
        logger.info("handle_image: è§£æå›¾åƒå¤„ç†APIçš„å“åº”")
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        user_params = self.params_cache.get(user_id, {})
        prompt = user_params.get('prompt', self.image_sum_prompt)

        logger.debug(f"[sum4all] Checking image_sum_service value: '{self.image_sum_service}'") # ADDED DEBUG LOG
        if self.image_sum_service == "openai":
            api_key = self.open_ai_api_key
            api_base = f"{self.open_ai_api_base}/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            model = "gpt-4o-mini"
        elif self.image_sum_service == "azure":
            api_key = self.open_ai_api_key
            api_base = f"{self.open_ai_api_base}/openai/deployments/{self.azure_deployment_id}/chat/completions?api-version=2024-02-15-preview"
            headers = {
                "Content-Type": "application/json",
                "api-key": api_key
            }
            model = "gpt-4o-mini"
        elif self.image_sum_service == "xunfei":
            api_key = self.xunfei_api_key
            api_base = "https://spark.sum4all.site/v1/chat/completions"
            model = "spark-chat-vision"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
        elif self.image_sum_service == "sum4all":
            api_key = self.sum4all_key
            api_base = "https://pro.sum4all.site/v1/chat/completions"
            model = "sum4all-vision"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
        elif self.image_sum_service == "gemini":
            api_key = self.gemini_key
            api_base = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
            payload = {
                "contents": [
                    {
                        "parts": [
                            {"text": prompt},
                            {
                                "inline_data": {
                                    "mime_type":"image/png",
                                    "data": base64_image
                                }
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "maxOutputTokens": 800
                }
            }
            headers = {
                "Content-Type": "application/json",
                "x-goog-api-key": api_key
            }
        elif self.image_sum_service == "aliyun":
            api_key = self.aliyun_key
            api_base = self.aliyun_base_url
            
            if has_openai:
                # ä½¿ç”¨OpenAIå®¢æˆ·ç«¯åº“
                try:
                    client = OpenAI(
                        api_key=api_key,
                        base_url=api_base
                    )
                    
                    completion = client.chat.completions.create(
                        model=self.aliyun_vl_model,
                        messages=[
                            {"role": "system", "content": self.image_sum_prompt},
                            {"role": "user", "content": [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}]}
                        ],
                        temperature=0.7,
                        max_tokens=2000
                    )
                    
                    reply_content = completion.choices[0].message.content
                    
                except Exception as e:
                    logger.error(f"Error using OpenAI client for Aliyun API: {e}")
                    # å¤±è´¥åå›é€€åˆ°ç›´æ¥ä½¿ç”¨requests
                    headers = {
                        'Content-Type': 'application/json',
                        'Authorization': f'Bearer {api_key}'
                    }
                    payload = {
                        "model": self.aliyun_vl_model,
                        "messages": [
                            {"role": "system", "content": self.image_sum_prompt},
                            {"role": "user", "content": [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}]}
                        ],
                        "temperature": 0.7,
                        "max_tokens": 2000
                    }
                    response = requests.post(
                        api_base if "/chat/completions" in api_base else f"{api_base}/chat/completions",
                        headers=headers,
                        json=payload,
                        verify=False,
                        timeout=30
                    )
                    response.raise_for_status()
                    result = response.json()
                    if "choices" in result and len(result["choices"]) > 0:
                        reply_content = result["choices"][0]["message"]["content"]
                    else:
                        logger.error("é˜¿é‡Œç™¾ç‚¼ API è¿”å›æ ¼å¼é”™è¯¯")
                        reply_content = "æ€»ç»“å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
            # The following else block is the fallback for Aliyun if has_openai is false or fails
            else: # This else corresponds to 'if has_openai' within the aliyun block
                logger.info("[sum4all][aliyun_image] Using requests directly for Aliyun...")
                headers = {
                    'Content-Type': 'application/json',
                    'Authorization': f'Bearer {api_key}'
                }
                payload = {
                    "model": self.aliyun_vl_model,
                    "messages": [
                        {"role": "system", "content": self.image_sum_prompt},
                        {"role": "user", "content": [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}]}
                    ],
                    "temperature": 0.7,
                    "max_tokens": 2000
                }
                try:
                    response = requests.post(
                        api_base if "/chat/completions" in api_base else f"{api_base}/chat/completions",
                        headers=headers,
                        json=payload,
                        verify=False,
                        timeout=30
                    )
                    response.raise_for_status()
                    result = response.json()
                    if "choices" in result and len(result["choices"]) > 0:
                        reply_content = result["choices"][0]["message"]["content"]
                    else:
                        logger.error("[sum4all][aliyun_image] Aliyun API response format error (requests).")
                        reply_content = "æ€»ç»“å¤±è´¥ï¼Œè¯·ç¨åé‡è¯• (requests)"
                except requests.exceptions.RequestException as e:
                    logger.error(f"[sum4all][aliyun_image] Error calling Aliyun API via requests: {e}")
                    reply_content = "è°ƒç”¨é˜¿é‡Œç™¾ç‚¼APIå¤±è´¥ (requests)"

        # <<<<< CORRECTED SFLOW BLOCK STARTS HERE >>>>>
        elif self.image_sum_service == "sflow":
            logger.info("[sum4all][sflow_image] Handling SiliconFlow image request...")
            api_key = self.siliconflow_key
            api_base = self.siliconflow_base_url
            model = self.siliconflow_vl_model # Use the specific VL model

            if not api_key or not api_base or not model:
                 logger.error("[sum4all][sflow_image] SiliconFlow configuration (key, base_url, or vl_model) is missing.")
                 reply_content = "SiliconFlow é…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•å¤„ç†å›¾ç‰‡"
            else:
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {api_key}"
                }
                payload = {
                    "model": model,
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                            ]
                        }
                    ],
                    "temperature": 0.7,
                    "max_tokens": 1500
                }
                logger.debug(f"[sum4all][sflow_image] Sending payload: {payload}")
                reply_content = "å¤„ç†å›¾ç‰‡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯" # Default error
                try:
                    logger.info(f"[sum4all][sflow_image] Sending request to {api_base}/chat/completions")
                    response = requests.post(
                        f"{api_base}/chat/completions",
                        headers=headers,
                        json=payload,
                        verify=False,
                        timeout=60
                    )
                    logger.info(f"[sum4all][sflow_image] Received response status: {response.status_code}")
                    response.raise_for_status()
                    response_data = response.json()
                    logger.debug(f"[sum4all][sflow_image] Response data: {response_data}")
                    if "choices" in response_data and len(response_data["choices"]) > 0:
                        result = response_data["choices"][0].get("message", {}).get("content")
                        if result:
                            reply_content = result
                            logger.info("[sum4all][sflow_image] Successfully extracted content from response.")
                        else:
                            logger.error("[sum4all][sflow_image] 'content' missing in response choice.")
                            reply_content = "æ— æ³•ä» SiliconFlow API è·å–æœ‰æ•ˆçš„å“åº”å†…å®¹ (content missing)"
                    else:
                        logger.error("[sum4all][sflow_image] 'choices' missing or empty in response.")
                        reply_content = "æ— æ³•ä» SiliconFlow API è·å–æœ‰æ•ˆçš„å“åº”å†…å®¹ (choices missing)"
                except requests.exceptions.Timeout:
                    logger.error("[sum4all][sflow_image] Request timed out.")
                    reply_content = "è°ƒç”¨ SiliconFlow API å¤„ç†å›¾ç‰‡è¶…æ—¶"
                except requests.exceptions.RequestException as e:
                    logger.error(f"[sum4all][sflow_image] API request error: {e}")
                    if hasattr(e, 'response') and e.response is not None:
                        logger.error(f"[sum4all][sflow_image] Response status code: {e.response.status_code}")
                        logger.error(f"[sum4all][sflow_image] Response content: {e.response.text}")
                        reply_content = f"è°ƒç”¨ SiliconFlow API å¤„ç†å›¾ç‰‡å‡ºé”™: Status {e.response.status_code}"
                    else:
                        reply_content = f"è°ƒç”¨ SiliconFlow API å¤„ç†å›¾ç‰‡æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {str(e)}"

        # <<<<< END OF CORRECTED SFLOW BLOCK >>>>>
        else: # Final else for the main service selection
            logger.error(f"æœªçŸ¥çš„image_sum_serviceé…ç½®: {self.image_sum_service}")
            return

        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.image_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®"
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    
    def handle_sum4all(self, content, e_context):
        logger.info('Handling Sum4All request...')
        # ç”±äºsum4all.siteæœåŠ¡ä¸å¯ç”¨ï¼Œæˆ‘ä»¬æ”¹ç”¨OpenAI API
        api_key = self.open_ai_api_key
        api_base = self.open_ai_api_base
        model = self.model
        
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        user_params = self.params_cache.get(user_id, {})
        isgroup = e_context["context"].get("isgroup", False)
        prompt = user_params.get('prompt', self.url_sum_prompt)
        
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        }
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç½‘é¡µå†…å®¹æ€»ç»“ä¸“å®¶ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ€»ç»“ç½‘é¡µå†…å®¹ï¼š
1. é¦–å…ˆç”¨ä¸€å¥è¯æ€»ç»“æ–‡ç« çš„æ ¸å¿ƒè§‚ç‚¹ï¼ˆ30å­—ä»¥å†…ï¼‰
2. ç„¶ååˆ—å‡º3-5ä¸ªå…³é”®è¦ç‚¹
3. ä½¿ç”¨emojiè®©è¡¨è¾¾æ›´ç”ŸåŠ¨
4. ä¿æŒä¸“ä¸šã€å®¢è§‚çš„è¯­æ°”"""

        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = f"""è¯·æ€»ç»“ä»¥ä¸‹ç½‘é¡µå†…å®¹ï¼š
{prompt}

ç½‘é¡µé“¾æ¥ï¼š{content}"""

        # æ„å»ºè¯·æ±‚ä½“
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.7,
            "max_tokens": 1000
        }

        try:
            response = requests.post(
                f"{api_base}/chat/completions",
                headers=headers,
                json=payload,
                verify=False  # ç¦ç”¨SSLéªŒè¯
            )
            response.raise_for_status()
            response_data = response.json()
            
            if "choices" in response_data and len(response_data["choices"]) > 0:
                content = response_data["choices"][0]["message"]["content"]
                self.params_cache[user_id]['content'] = content
                
                # å°è¯•ä»å†…å®¹ä¸­æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œï¼‰
                lines = content.split('\n')
                if lines:
                    title = lines[0].strip()
                    self.params_cache[user_id]['title'] = title
                
                additional_content = ""
                if title:
                    additional_content += f"{title}\n\n"
                reply_content = additional_content + content
            else:
                reply_content = "æ— æ³•è·å–æœ‰æ•ˆçš„å“åº”å†…å®¹"

        except requests.exceptions.RequestException as e:
            logger.error(f"Error calling OpenAI API: {e}")
            reply_content = f"è°ƒç”¨ OpenAI API æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

        reply = Reply()
        reply.type = ReplyType.TEXT
        if not self.url_sum_qa_enabled:
            reply.content = remove_markdown(reply_content)
        elif isgroup or not self.note_enabled:
            reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.url_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®"
        elif self.note_enabled:
            reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.url_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®\nğŸ’¡è¾“å…¥{self.note_prefix}+ç¬”è®°ï¼Œå¯ä¿å­˜åˆ°{self.note_service}"
        
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS

    def handle_gemini(self, content, e_context):
        logger.info('Handling Gemini request...')
        # è·å–ç½‘é¡µå†…å®¹
        webpage_content = self.get_webpage_content(content)
        if not webpage_content:
            reply_content = "æ— æ³•è·å–ç½‘é¡µå†…å®¹ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆ"
        else:
            api_key = self.gemini_key
            model = "gemini"
            api_base = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
            
            msg: ChatMessage = e_context["context"]["msg"]
            user_id = msg.from_user_id
            user_params = self.params_cache.get(user_id, {})
            isgroup = e_context["context"].get("isgroup", False)
            prompt = user_params.get('prompt', self.url_sum_prompt)
            
            headers = {
                'Content-Type': 'application/json',
                'x-goog-api-key': api_key
            }
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç½‘é¡µå†…å®¹æ€»ç»“ä¸“å®¶ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ€»ç»“ç½‘é¡µå†…å®¹ï¼š
1. é¦–å…ˆç”¨ä¸€å¥è¯æ€»ç»“æ–‡ç« çš„æ ¸å¿ƒè§‚ç‚¹ï¼ˆ30å­—ä»¥å†…ï¼‰
2. ç„¶ååˆ—å‡º3-5ä¸ªå…³é”®è¦ç‚¹
3. ä½¿ç”¨emojiè®©è¡¨è¾¾æ›´ç”ŸåŠ¨
4. ä¿æŒä¸“ä¸šã€å®¢è§‚çš„è¯­æ°”"""
